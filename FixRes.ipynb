{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class ProgressMeter(object):\n",
    "  def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "    self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "    self.meters = meters\n",
    "    self.prefix = prefix\n",
    "\n",
    "  def display(self, batch):\n",
    "    entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "    entries += [str(meter) for meter in self.meters]\n",
    "    print('\\t'.join(entries))\n",
    "\n",
    "  def _get_batch_fmtstr(self, num_batches):\n",
    "    num_digits = len(str(num_batches // 1))\n",
    "    fmt = '{:' + str(num_digits) + 'd}'\n",
    "    return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self, name, fmt=':f'):\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "    self.epoch_sum = 0\n",
    "    self.epoch_count = 0\n",
    "    self.epoch_avg = 0\n",
    "\n",
    "  def reset(self):\n",
    "#     self.val = 0\n",
    "    self.avg = 0\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "    self.epoch_sum += val * n\n",
    "    self.epoch_count += n\n",
    "    self.epoch_avg = self.epoch_sum / self.epoch_count\n",
    "    \n",
    "  def __str__(self):\n",
    "    fmtstr = '{name} {avg' + self.fmt + '} ({epoch_avg' + self.fmt + '})'\n",
    "    return fmtstr.format(**self.__dict__)\n",
    "  \n",
    "def save_checkpoint(state, is_best, filename='checkpoint_conv.pth.tar'):\n",
    "  torch.save(state, filename)\n",
    "  if is_best:\n",
    "    shutil.copyfile(filename, 'model_best_conv.pth.tar')\n",
    "    \n",
    "def imshow(img):\n",
    "  unnormalize = transforms.Normalize((-0.4914/0.247, -0.4822/0.243, -0.4465/0.261), (1/0.247, 1/0.243, 1/0.261))\n",
    "  img = unnormalize(img)\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(model, input_size, batch_size=-1, device=\"cuda\"):\n",
    "\n",
    "    def register_hook(module):\n",
    "\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "            and not (module == model)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    device = device.lower()\n",
    "    assert device in [\n",
    "        \"cuda\",\n",
    "        \"cpu\",\n",
    "    ], \"Input device is not valid, please specify 'cuda' or 'cpu'\"\n",
    "\n",
    "    if device == \"cuda\" and torch.cuda.is_available():\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]\n",
    "    print(x[0].shape)\n",
    "    # print(type(x[0]))\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "    print(line_new)\n",
    "    print(\"================================================================\")\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        print(line_new)\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(input_size) * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. / (1024 ** 2.))  # x2 for gradients\n",
    "    total_params_size = abs(total_params.numpy() * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    print(\"================================================================\")\n",
    "    print(\"Total params: {0:,}\".format(total_params))\n",
    "    print(\"Trainable params: {0:,}\".format(trainable_params))\n",
    "    print(\"Non-trainable params: {0:,}\".format(total_params - trainable_params))\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Input size (MB): %0.2f\" % total_input_size)\n",
    "    print(\"Forward/backward pass size (MB): %0.2f\" % total_output_size)\n",
    "    print(\"Params size (MB): %0.2f\" % total_params_size)\n",
    "    print(\"Estimated Total Size (MB): %0.2f\" % total_size)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    # return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FixRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/facebookresearch/FixRes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd /workspace/FixRes\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt  update\n",
    "# !apt install wget\n",
    "# !wget https://dl.fbaipublicfiles.com/FixRes_data/FixRes_Pretrained_Models/ResNeXt_101_32x48d.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from imnet_evaluate.resnext_wsl import *\n",
    "\n",
    "model = resnext101_32x8d_wsl(progress=False)\n",
    "\n",
    "# pretrained_dict = torch.load('ResNeXt_101_32x48d.pth', map_location='cpu')['model']\n",
    "\n",
    "# model_dict = model.state_dict()\n",
    "# for k in model_dict.keys():\n",
    "#   if(('module.'+k) in pretrained_dict.keys()):\n",
    "#     model_dict[k] = pretrained_dict.get(('module.'+k))\n",
    "    \n",
    "# model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "## Settings\n",
    "batch_size = 28\n",
    "# val_ratio = 10000/50000\n",
    "batch_print_freq = 500\n",
    "start_epoch = 0\n",
    "# epochs = 1\n",
    "\n",
    "###################################################\n",
    "## Load Data\n",
    "# dataloaders = {}\n",
    "# dataloaders['train'], dataloaders['val'] = get_train_val_loaders('./data', batch_size, val_ratio)\n",
    "# trainloader, _ =  get_train_val_loaders('./data', batch_size, val_ratio)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "from imnet_finetune.transforms import get_transforms\n",
    "transformation = get_transforms(input_size=320,test_size=320, kind='full', crop=True, need=('train', 'val'), backbone=None)\n",
    "trainset = torchvision.datasets.ImageFolder('/workspace/data/train', transform=transformation['val'])\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=2)\n",
    "print(trainset)\n",
    "\n",
    "###################################################\n",
    "## Load Model\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define/load model\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 10)\n",
    "# Send model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function (criterion) and optimizer and LR scheduler\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "# NOTE: define optimizer after sending model to GPU. May lead to error otherwise.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
    "#   lrscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDNN_LOGINFO_DBG=1\n",
    "%env CUDNN_LOGDEST_DBG=/workspace/FixRes/logs/cudnn1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Profiling Training on GPU\n",
    "losses = AverageMeter('Loss', ':.4e')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "# set to train mode\n",
    "model.train()\n",
    "\n",
    "# batch times\n",
    "batchTimes = []\n",
    "\n",
    "trainiter = iter(trainloader)\n",
    "# specify which batch you want to profile\n",
    "batches = 1\n",
    "isProfile = False\n",
    "for i in range(batches):\n",
    "    images, target = trainiter.next()\n",
    "    # Time\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    images = images.to(device)\n",
    "    target = target.to(device)\n",
    "  \n",
    "#     if i == (batches-1):\n",
    "#         isProfile = True\n",
    "    \n",
    "#     with torch.autograd.profiler.profile(enabled=isProfile,use_cuda=True) as prof:\n",
    "    output = model(images)\n",
    "    loss = criterion(output, target)\n",
    "  # compute gradients and do kprop \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # time\n",
    "    torch.cuda.synchronize()\n",
    "    end1 = time.time()\n",
    "    batchTimes.append(end1-start)\n",
    "    \n",
    "    # measure accuracy and record loss\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    losses.update(loss.item(), images.size(0))\n",
    "    top1.update(acc1[0], images.size(0))\n",
    "    top5.update(acc5[0], images.size(0))\n",
    "    \n",
    "    print(' * TRAIN: Acc@1 {top1.epoch_avg:.3f} Acc@5 {top5.epoch_avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    \n",
    "# print(prof)\n",
    "print(batchTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNeXt101_32x48d - batch 2 - avg time\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(batchTimes)\n",
    "df.mean()\n",
    "## Nvidia\n",
    "# [0.540184736251831, 0.5099315643310547, 0.5100128650665283, 0.5107409954071045, 0.5070912837982178, 0.5088832378387451, 0.508690357208252, 0.5116229057312012, 0.509019136428833, 0.5115687847137451, 0.5111806392669678, 0.5110089778900146, 0.5101885795593262, 0.5084385871887207, 0.5120565891265869, 0.5119218826293945, 0.511404275894165, 0.512099027633667, 0.5103232860565186, 0.5099480152130127, 0.5124289989471436, 0.5113327503204346, 0.5095608234405518, 0.5098636150360107, 0.510570764541626, 0.511298418045044, 0.5104150772094727, 0.5117084980010986, 0.5108726024627686, 0.5109071731567383]\n",
    "# 0.511509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNeXt101_32x8d - batch 28 - avg time\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(batchTimes)\n",
    "df.mean()\n",
    "## Nvidia\n",
    "# [0.6732978820800781, 0.6745915412902832, 0.6740171909332275, 0.6741843223571777, 0.6739389896392822, 0.6741132736206055, 0.6734766960144043, 0.6736109256744385, 0.6746206283569336, 0.6754834651947021, 0.6758608818054199, 0.674668550491333, 0.6746973991394043, 0.6754088401794434, 0.6756057739257812, 0.6759140491485596, 0.6750330924987793, 0.6748614311218262, 0.6749403476715088, 0.6774365901947021, 0.6748318672180176, 0.6770632266998291, 0.6754391193389893, 0.6777341365814209, 0.6746277809143066, 0.6782195568084717, 0.6738636493682861, 0.6777245998382568, 0.6749558448791504, 0.6749212741851807]\n",
    "# 0.675171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
