{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      " ========================ROCm System Management Interface========================\r\n",
      "================================================================================\r\n",
      "GPU  Temp   AvgPwr  SCLK     MCLK    Fan   Perf  PwrCap  VRAM%  GPU%  \r\n",
      "1    31.0c  27.0W   1340Mhz  878Mhz  0.0%  auto  225.0W    0%   0%    \r\n",
      "2    29.0c  18.0W   939Mhz   351Mhz  0.0%  auto  225.0W    0%   0%    \r\n",
      "================================================================================\r\n",
      "==============================End of ROCm SMI Log ==============================\r\n"
     ]
    }
   ],
   "source": [
    "!/opt/rocm/bin/rocm-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_loaders(data_dir, batch_size, val_ratio, shuffle=True, \n",
    "                          num_workers=0, sampler=SubsetRandomSampler, pin_memory=False):\n",
    "  random_seed =1928\n",
    "  # basic essential transformations\n",
    "  normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "  \n",
    "  train_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.RandomRotation(10),\n",
    "                                        transforms.ToTensor(), \n",
    "                                        normalize])\n",
    "\n",
    "#   test_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        normalize])\n",
    "  \n",
    "  trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=train_transform)\n",
    "#   valset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=False, transform=transform)\n",
    "\n",
    "  num_train = len(trainset)\n",
    "  indices = list(range(num_train))\n",
    "  split = int(np.floor(val_ratio * num_train))\n",
    "\n",
    "  if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "  train_idx, val_idx = indices[split:], indices[:split]\n",
    "  print(\"Training set size:\", len(train_idx), \"Validation set size:\", len(val_idx))\n",
    "  trainsampler = sampler(train_idx)\n",
    "  valsampler = sampler(val_idx)\n",
    "\n",
    "  trainloader = DataLoader(trainset, batch_size=batch_size, sampler=trainsampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "  valloader = DataLoader(trainset, batch_size=batch_size, sampler=valsampler, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "  return (trainloader, valloader)\n",
    "\n",
    "\n",
    "# trainloader, valloader = get_train_val_loaders('./data', batch_size, False, 4242, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class ProgressMeter(object):\n",
    "  def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "    self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "    self.meters = meters\n",
    "    self.prefix = prefix\n",
    "\n",
    "  def display(self, batch):\n",
    "    entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "    entries += [str(meter) for meter in self.meters]\n",
    "    print('\\t'.join(entries))\n",
    "\n",
    "  def _get_batch_fmtstr(self, num_batches):\n",
    "    num_digits = len(str(num_batches // 1))\n",
    "    fmt = '{:' + str(num_digits) + 'd}'\n",
    "    return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self, name, fmt=':f'):\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "    self.epoch_sum = 0\n",
    "    self.epoch_count = 0\n",
    "    self.epoch_avg = 0\n",
    "\n",
    "  def reset(self):\n",
    "#     self.val = 0\n",
    "    self.avg = 0\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "    self.epoch_sum += val * n\n",
    "    self.epoch_count += n\n",
    "    self.epoch_avg = self.epoch_sum / self.epoch_count\n",
    "    \n",
    "  def __str__(self):\n",
    "    fmtstr = '{name} {avg' + self.fmt + '} ({epoch_avg' + self.fmt + '})'\n",
    "    return fmtstr.format(**self.__dict__)\n",
    "  \n",
    "def save_checkpoint(state, is_best, filename='checkpoint_conv.pth.tar'):\n",
    "  torch.save(state, filename)\n",
    "  if is_best:\n",
    "    shutil.copyfile(filename, 'model_best_conv.pth.tar')\n",
    "    \n",
    "def imshow(img):\n",
    "  unnormalize = transforms.Normalize((-0.4914/0.247, -0.4822/0.243, -0.4465/0.261), (1/0.247, 1/0.243, 1/0.261))\n",
    "  img = unnormalize(img)\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt  update\n",
    "# !apt install wget\n",
    "# !wget https://dl.fbaipublicfiles.com/FixRes_data/FixRes_Pretrained_Models/ResNeXt_101_32x48d.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from imnet_evaluate.resnext_wsl import resnext101_32x48d_wsl\n",
    "\n",
    "model = resnext101_32x48d_wsl(progress=True)\n",
    "\n",
    "pretrained_dict = torch.load('ResNeXt_101_32x48d.pth', map_location='cpu')['model']\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "for k in model_dict.keys():\n",
    "  if(('module.'+k) in pretrained_dict.keys()):\n",
    "    model_dict[k] = pretrained_dict.get(('module.'+k))\n",
    "    \n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Training set size: 40000 Validation set size: 10000\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "## Settings\n",
    "batch_size = 4\n",
    "val_ratio = 10000/50000\n",
    "batch_print_freq = 500\n",
    "start_epoch = 0\n",
    "# epochs = 1\n",
    "\n",
    "###################################################\n",
    "## Load Data\n",
    "# dataloaders = {}\n",
    "# dataloaders['train'], dataloaders['val'] = get_train_val_loaders('./data', batch_size, val_ratio)\n",
    "trainloader, _ =  get_train_val_loaders('./data', batch_size, val_ratio)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# from imnet_finetune.transforms import get_transforms\n",
    "# transformation = get_transforms(input_size=320,test_size=320, kind='full', crop=True, need=('train', 'val'), backbone=None)\n",
    "# trainset = torchvision.datasets.ImageFolder('/workspace/data/train', transform=transformation['val'])\n",
    "# trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=2)\n",
    "# print(trainset)\n",
    "\n",
    "###################################################\n",
    "## Load Model\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define/load model\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "# Send model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function (criterion) and optimizer and LR scheduler\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "# NOTE: define optimizer after sending model to GPU. May lead to error otherwise.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
    "#   lrscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "## Profiling Training on GPU\n",
    "losses = AverageMeter('Loss', ':.4e')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "# set to train mode\n",
    "model.train()\n",
    "\n",
    "trainiter = iter(trainloader)\n",
    "# specify which batch you want to profile\n",
    "batches = 1\n",
    "isProfile = False\n",
    "for i in range(batches):\n",
    "    images, target = trainiter.next()\n",
    "    images = images.to(device)\n",
    "    target = target.to(device)\n",
    "    print(\"data loaded\")\n",
    "#     if i == (batches-1):\n",
    "#         isProfile = True\n",
    "    \n",
    "#     with torch.autograd.profiler.profile(enabled=isProfile,use_cuda=True) as prof:\n",
    "    output = model(images)\n",
    "    print(\"output done\")\n",
    "    loss = criterion(output, target)\n",
    "    print(\"loss done\")\n",
    "  # compute gradients and do kprop \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"backprop done\")\n",
    "  \n",
    "   # measure accuracy and record loss\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "    losses.update(loss.item(), images.size(0))\n",
    "    top1.update(acc1[0], images.size(0))\n",
    "    top5.update(acc5[0], images.size(0))\n",
    "    \n",
    "    print(' * TRAIN: Acc@1 {top1.epoch_avg:.3f} Acc@5 {top5.epoch_avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    \n",
    "# print(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
